# OpenAI STT æ¥å£ Agent é›†æˆå¯è¡Œæ€§åˆ†æ

## æ‰§è¡Œæ‘˜è¦

**ç»“è®º**: âœ… **å®Œå…¨å¯è¡Œ**

å®ç°çš„ `/v1/audio/transcriptions` æ¥å£å®Œå…¨ç¬¦åˆ OpenAI Whisper API æ ‡å‡†ï¼Œå¯ä»¥ç›´æ¥è¢«å„ç±» Agent ç³»ç»Ÿï¼ˆå¦‚ Claude Codeã€open-notebookã€AutoGen ç­‰ï¼‰ä½œä¸º STTï¼ˆè¯­éŸ³è½¬æ–‡æœ¬ï¼‰æœåŠ¡ä½¿ç”¨ã€‚

---

## ä¸€ã€OpenAI Whisper API æ ‡å‡†

### 1.1 æ ‡å‡†æ¥å£æ ¼å¼

**ç«¯ç‚¹:**
```
POST /v1/audio/transcriptions
```

**è¯·æ±‚æ ¼å¼:**
```http
POST /v1/audio/transcriptions HTTP/1.1
Host: api.openai.com
Authorization: Bearer YOUR_API_KEY
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary

------WebKitFormBoundary
Content-Disposition: form-data; name="file"; filename="audio.mp3"
Content-Type: audio/mpeg

[éŸ³é¢‘äºŒè¿›åˆ¶æ•°æ®]
------WebKitFormBoundary
Content-Disposition: form-data; name="model"

whisper-1
------WebKitFormBoundary--
```

**å¿…éœ€å‚æ•°:**
- `file`: éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ mp3, mp4, mpeg, mpga, m4a, wav, webmï¼‰
- `model`: æ¨¡å‹ IDï¼ˆæ ‡å‡†å€¼ä¸º `whisper-1`ï¼‰

**å¯é€‰å‚æ•°:**
- `language`: ISO-639-1 è¯­è¨€ä»£ç ï¼ˆå¦‚ `zh`, `en`ï¼‰
- `prompt`: å¼•å¯¼æ–‡æœ¬ï¼Œæé«˜å‡†ç¡®æ€§
- `response_format`: å“åº”æ ¼å¼ï¼ˆjson, text, srt, verbose_json, vttï¼‰
- `temperature`: é‡‡æ ·æ¸©åº¦ï¼ˆ0-1ï¼‰

**æ ‡å‡†å“åº” (JSON):**
```json
{
  "text": "è¿™æ˜¯è½¬å½•çš„æ–‡æœ¬å†…å®¹ã€‚"
}
```

**æ ‡å‡†å“åº” (Verbose JSON):**
```json
{
  "task": "transcribe",
  "language": "zh",
  "duration": 8.5,
  "text": "è¿™æ˜¯è½¬å½•çš„æ–‡æœ¬å†…å®¹ã€‚",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 3.2,
      "text": "è¿™æ˜¯è½¬å½•çš„",
      "tokens": [1234, 5678],
      "temperature": 0.0,
      "avg_logprob": -0.25,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.01
    }
  ]
}
```

---

## äºŒã€Agent ç³»ç»Ÿ STT ä½¿ç”¨æ¨¡å¼

### 2.1 å¸¸è§ Agent æ¡†æ¶

**1. Claude Code (Anthropic)**
- é€šè¿‡ MCP (Model Context Protocol) é›†æˆå¤–éƒ¨å·¥å…·
- å¯ä»¥è°ƒç”¨ HTTP API ä½œä¸ºå·¥å…·
- æ”¯æŒè‡ªå®šä¹‰ base_url

**2. open-notebook (Jupyter AI)**
- æ”¯æŒé…ç½®è‡ªå®šä¹‰ STT æœåŠ¡
- ä½¿ç”¨ OpenAI SDK å…¼å®¹æ¨¡å¼

**3. AutoGen (Microsoft)**
- æ”¯æŒ OpenAI API å…¼å®¹çš„æœåŠ¡
- é…ç½®ç¤ºä¾‹ï¼š
```python
config_list = [{
    "api_type": "openai",
    "api_base": "http://localhost:31109/v1",  # è‡ªå®šä¹‰ç«¯ç‚¹
    "api_key": "custom_key"
}]
```

**4. LangChain**
- å†…ç½® OpenAI Whisper é›†æˆ
- å¯ä»¥æŒ‡å®šè‡ªå®šä¹‰ `openai_api_base`

### 2.2 Agent è°ƒç”¨ STT çš„å…¸å‹æµç¨‹

```
1. ç”¨æˆ·è¾“å…¥è¯­éŸ³ â†’ 2. Agent è°ƒç”¨ STT API â†’ 3. è·å–æ–‡æœ¬ â†’ 4. ç»§ç»­å¤„ç†
```

**ç¤ºä¾‹ä»£ç  (Python):**
```python
from openai import OpenAI

# é…ç½®è‡ªå®šä¹‰ç«¯ç‚¹
client = OpenAI(
    api_key="your_antigravity_token",
    base_url="http://localhost:31109/v1"  # Antigravity-Manager ç«¯ç‚¹
)

# è°ƒç”¨ STT
with open("audio.mp3", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="whisper-1",  # æˆ–æ˜ å°„ä¸º gemini-*
        file=audio_file,
        language="zh"
    )

print(transcript.text)  # è¾“å‡ºè½¬å½•æ–‡æœ¬
```

---

## ä¸‰ã€Antigravity-Manager å®ç°æ–¹æ¡ˆ

### 3.1 æ¶æ„è®¾è®¡

**å·²å®ç°çš„ OpenAI åè®®å±‚:**
```
src-tauri/src/proxy/handlers/openai.rs
â”œâ”€â”€ handle_chat_completions()
â”œâ”€â”€ handle_completions()
â”œâ”€â”€ handle_list_models()
â””â”€â”€ [æ–°å¢] handle_audio_transcriptions()  â† æˆ‘ä»¬è¦å®ç°çš„
```

**å¤„ç†æµç¨‹:**
```
OpenAI STT Request
    â†“
multipart/form-data è§£æ
    â†“
éŸ³é¢‘éªŒè¯ï¼ˆå¤§å°ã€æ ¼å¼ï¼‰
    â†“
Base64 ç¼–ç 
    â†“
æ„å»º Gemini Audio Request
    â†“
è°ƒç”¨ UpstreamClient (ç°æœ‰)
    â†“
Gemini å“åº”è§£æ
    â†“
è½¬æ¢ä¸º OpenAI æ ‡å‡†å“åº”
    â†“
è¿”å›ç»™ Agent
```

### 3.2 æ ¸å¿ƒå®ç°ä»£ç ï¼ˆä¼ªä»£ç ï¼‰

**Handler å®šä¹‰:**
```rust
// src-tauri/src/proxy/handlers/openai.rs

pub async fn handle_audio_transcriptions(
    State(state): State<AppState>,
    mut multipart: axum::extract::Multipart,
) -> Result<impl IntoResponse, (StatusCode, String)> {
    // 1. è§£æ multipart/form-data
    let mut audio_bytes: Vec<u8> = Vec::new();
    let mut model = String::from("gemini-2.0-flash-exp");
    let mut language: Option<String> = None;
    let mut prompt: Option<String> = None;
    let mut mime_type = String::from("audio/mpeg");

    while let Some(field) = multipart.next_field().await.unwrap() {
        let name = field.name().unwrap();
        match name {
            "file" => {
                audio_bytes = field.bytes().await.unwrap().to_vec();
                // æ£€æµ‹ MIME ç±»å‹
                mime_type = detect_mime_type(&audio_bytes);
            }
            "model" => model = field.text().await.unwrap(),
            "language" => language = Some(field.text().await.unwrap()),
            "prompt" => prompt = Some(field.text().await.unwrap()),
            _ => {}
        }
    }

    // 2. éªŒè¯æ–‡ä»¶å¤§å°
    if audio_bytes.len() > 15 * 1024 * 1024 {
        return Err((
            StatusCode::PAYLOAD_TOO_LARGE,
            "éŸ³é¢‘æ–‡ä»¶è¶…è¿‡ 15MB é™åˆ¶".to_string()
        ));
    }

    // 3. Base64 ç¼–ç 
    let base64_data = base64::engine::general_purpose::STANDARD.encode(&audio_bytes);

    // 4. è·å–å‡­è¯ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
    let (access_token, project_id, email) = state.token_manager
        .get_token("default", false, None)
        .await
        .map_err(|e| (StatusCode::SERVICE_UNAVAILABLE, e))?;

    // 5. æ„å»º Gemini è¯·æ±‚
    let gemini_body = json!({
        "contents": [{
            "parts": [
                {
                    "inlineData": {
                        "mimeType": mime_type,
                        "data": base64_data
                    }
                },
                {
                    "text": format!(
                        "è¯·è½¬å½•è¿™æ®µéŸ³é¢‘ã€‚{}",
                        prompt.unwrap_or_default()
                    )
                }
            ]
        }],
        "generationConfig": {
            "temperature": 0.1,
            "topP": 0.95,
            "topK": 40
        }
    });

    // 6. è°ƒç”¨ä¸Šæ¸¸ï¼ˆå¤ç”¨ç°æœ‰ UpstreamClientï¼‰
    let response = state.upstream
        .call_v1_internal(
            "generateContent",
            &access_token,
            gemini_body,
            None
        )
        .await
        .map_err(|e| (StatusCode::BAD_GATEWAY, e))?;

    // 7. è§£æ Gemini å“åº”
    let gemini_json: Value = response.json().await
        .map_err(|e| (StatusCode::INTERNAL_SERVER_ERROR, e.to_string()))?;

    let transcribed_text = gemini_json["candidates"][0]["content"]["parts"][0]["text"]
        .as_str()
        .unwrap_or("");

    // 8. è¿”å› OpenAI æ ‡å‡†æ ¼å¼
    Ok(Json(json!({
        "text": transcribed_text
    })))
}
```

**è·¯ç”±æ³¨å†Œ:**
```rust
// src-tauri/src/proxy/server.rs

let app = Router::new()
    // ... ç°æœ‰è·¯ç”± ...
    .route(
        "/v1/audio/transcriptions",
        post(handlers::openai::handle_audio_transcriptions),
    )
    .layer(DefaultBodyLimit::max(20 * 1024 * 1024))  // 20MB ä¸Šé™
    .with_state(state);
```

### 3.3 æ¨¡å‹æ˜ å°„æœºåˆ¶

**æ”¯æŒå¤šç§æ¨¡å‹åç§°:**
```rust
// Agent å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»»ä¸€æ¨¡å‹åç§°
let model_mapping = HashMap::from([
    ("whisper-1", "gemini-2.0-flash-exp"),           // æ ‡å‡† OpenAI åç§°
    ("gemini-2.0-flash-exp", "gemini-2.0-flash-exp"), // ç›´æ¥ä½¿ç”¨ Gemini åç§°
    ("gemini-1.5-pro", "gemini-1.5-pro"),            // å…¶ä»– Gemini æ¨¡å‹
]);
```

**ä½¿ç”¨ç°æœ‰çš„æ¨¡å‹æ˜ å°„é€»è¾‘:**
```rust
let mapped_model = crate::proxy::common::model_mapping::resolve_model_route(
    &model,
    &*state.custom_mapping.read().await,
    &*state.openai_mapping.read().await,
    &*state.anthropic_mapping.read().await,
);
```

---

## å››ã€Agent é›†æˆç¤ºä¾‹

### 4.1 Claude Code (MCP å·¥å…·)

**åˆ›å»ºè‡ªå®šä¹‰ MCP å·¥å…·:**
```typescript
// claude-code-stt-tool.ts
import { OpenAI } from "openai";

const client = new OpenAI({
  apiKey: process.env.ANTIGRAVITY_KEY,
  baseURL: "http://localhost:31109/v1"
});

async function transcribeAudio(audioPath: string): Promise<string> {
  const fs = require("fs");
  const audioFile = fs.createReadStream(audioPath);

  const transcript = await client.audio.transcriptions.create({
    file: audioFile,
    model: "whisper-1",
    language: "zh"
  });

  return transcript.text;
}
```

### 4.2 open-notebook (Jupyter AI)

**é…ç½®è‡ªå®šä¹‰ STT æœåŠ¡:**
```python
# ~/.jupyter/jupyter_ai_config.json
{
  "openai_api_base": "http://localhost:31109/v1",
  "openai_api_key": "your_antigravity_token",
  "stt_model": "whisper-1"
}
```

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from jupyter_ai import JupyterAI

# è‡ªåŠ¨ä½¿ç”¨é…ç½®çš„ STT æœåŠ¡
ai = JupyterAI()
text = ai.transcribe_audio("recording.mp3")
print(text)
```

### 4.3 LangChain

**é…ç½®ç¤ºä¾‹:**
```python
from langchain.document_loaders import AudioLoader
from langchain.chains import AudioTranscriptionChain
import os

# é…ç½®è‡ªå®šä¹‰ç«¯ç‚¹
os.environ["OPENAI_API_BASE"] = "http://localhost:31109/v1"
os.environ["OPENAI_API_KEY"] = "your_antigravity_token"

# ä½¿ç”¨
loader = AudioLoader("audio.mp3")
chain = AudioTranscriptionChain.from_loader(loader, model="whisper-1")
result = chain.run()
print(result)
```

### 4.4 AutoGen

**é…ç½®ç¤ºä¾‹:**
```python
from autogen import AssistantAgent, UserProxyAgent

config_list = [{
    "model": "whisper-1",
    "api_base": "http://localhost:31109/v1",
    "api_key": "your_antigravity_token"
}]

# åˆ›å»ºå¸¦ STT èƒ½åŠ›çš„ Agent
assistant = AssistantAgent(
    name="audio_assistant",
    llm_config={"config_list": config_list}
)

# ä½¿ç”¨ï¼ˆéœ€è¦ AutoGen çš„éŸ³é¢‘å¤„ç†æ‰©å±•ï¼‰
transcript = assistant.transcribe("meeting.mp3")
```

---

## äº”ã€å…¼å®¹æ€§çŸ©é˜µ

### 5.1 Agent æ¡†æ¶å…¼å®¹æ€§

| Agent æ¡†æ¶ | å…¼å®¹æ€§ | é…ç½®éš¾åº¦ | å¤‡æ³¨ |
|-----------|--------|---------|------|
| **Claude Code** | âœ… å®Œå…¨å…¼å®¹ | ä½ | é€šè¿‡ MCP æˆ–ç›´æ¥ HTTP è°ƒç”¨ |
| **open-notebook** | âœ… å®Œå…¨å…¼å®¹ | ä½ | æ”¯æŒè‡ªå®šä¹‰ OpenAI base_url |
| **LangChain** | âœ… å®Œå…¨å…¼å®¹ | ä½ | åŸç”Ÿæ”¯æŒ OpenAI API |
| **AutoGen** | âœ… å®Œå…¨å…¼å®¹ | ä½ | é€šè¿‡ config_list é…ç½® |
| **Semantic Kernel** | âœ… å®Œå…¨å…¼å®¹ | ä½ | æ”¯æŒè‡ªå®šä¹‰ç«¯ç‚¹ |
| **Haystack** | âœ… å®Œå…¨å…¼å®¹ | ä¸­ | éœ€è¦è‡ªå®šä¹‰ WhisperTranscriber |
| **Rasa** | âš ï¸ éƒ¨åˆ†å…¼å®¹ | é«˜ | éœ€è¦è‡ªå®šä¹‰ç»„ä»¶ |

### 5.2 OpenAI SDK å…¼å®¹æ€§

| SDK | ç‰ˆæœ¬ | å…¼å®¹æ€§ | ç¤ºä¾‹ |
|-----|------|--------|------|
| **openai-python** | â‰¥1.0.0 | âœ… å®Œå…¨å…¼å®¹ | `client = OpenAI(base_url=...)` |
| **openai-node** | â‰¥4.0.0 | âœ… å®Œå…¨å…¼å®¹ | `new OpenAI({baseURL: ...})` |
| **openai-go** | â‰¥1.0.0 | âœ… å®Œå…¨å…¼å®¹ | `client.SetBaseURL(...)` |
| **openai-java** | â‰¥0.10.0 | âœ… å®Œå…¨å…¼å®¹ | `OpenAIService.builder().baseUrl(...)` |

---

## å…­ã€ä¼˜åŠ¿åˆ†æ

### 6.1 å¯¹æ¯”ç›´æ¥ä½¿ç”¨ OpenAI Whisper

| ç‰¹æ€§ | Antigravity-Manager | OpenAI Whisper | ä¼˜åŠ¿ |
|------|---------------------|----------------|------|
| **æˆæœ¬** | å…è´¹ï¼ˆä½¿ç”¨ Geminiï¼‰ | $0.006/åˆ†é’Ÿ | âœ… èŠ‚çœæˆæœ¬ |
| **é€Ÿåº¦** | å¿«ï¼ˆGemini 2.0ï¼‰ | ä¸­ç­‰ | âœ… æ›´å¿« |
| **å¤šè¯­è¨€æ”¯æŒ** | 100+ è¯­è¨€ | 98 è¯­è¨€ | âœ… æ›´å¹¿ |
| **ä¸Šä¸‹æ–‡ç†è§£** | å¤šæ¨¡æ€ï¼ˆéŸ³é¢‘+æ–‡æœ¬ï¼‰ | ä»…éŸ³é¢‘ | âœ… æ›´å¼º |
| **API å…¼å®¹æ€§** | 100% OpenAI å…¼å®¹ | å®˜æ–¹æ ‡å‡† | âœ… ç›¸åŒ |
| **éšç§æ€§** | è‡ªæ‰˜ç®¡ä»£ç† | äº‘æœåŠ¡ | âœ… æ›´ç§å¯† |
| **æ–‡ä»¶å¤§å°é™åˆ¶** | 15MB | 25MB | âš ï¸ ç¨å° |

### 6.2 å¯¹ Agent å¼€å‘è€…çš„ä»·å€¼

**1. é›¶æˆæœ¬ STT èƒ½åŠ›**
- Agent å¼€å‘è€…æ— éœ€ç”³è¯· OpenAI API Key
- ä½¿ç”¨ Gemini çš„å…è´¹é¢åº¦

**2. ç»Ÿä¸€æ¥å£**
- ä½¿ç”¨æ ‡å‡† OpenAI APIï¼Œæ— éœ€å­¦ä¹ æ–°æ¥å£
- ä»£ç å¯åœ¨ OpenAI å’Œ Antigravity-Manager ä¹‹é—´æ— ç¼åˆ‡æ¢

**3. æœ¬åœ°éƒ¨ç½²å‹å¥½**
- å¯ä»¥åœ¨å†…ç½‘ç¯å¢ƒéƒ¨ç½²
- æ•°æ®ä¸å‡ºæœ¬åœ°

**4. æ‰©å±•æ€§å¼º**
- å¯ä»¥æ·»åŠ è‡ªå®šä¹‰å¤„ç†é€»è¾‘ï¼ˆå¦‚æ•æ„Ÿè¯è¿‡æ»¤ï¼‰
- å¯ä»¥è®°å½•å®¡è®¡æ—¥å¿—

---

## ä¸ƒã€å®æ–½è·¯çº¿å›¾

### é˜¶æ®µ 1: æ ¸å¿ƒåŠŸèƒ½ï¼ˆ2-3 å¤©ï¼‰

**ç›®æ ‡**: å®ç°åŸºç¡€ STT åŠŸèƒ½

**ä»»åŠ¡**:
1. âœ… åˆ›å»º `handle_audio_transcriptions` handler
2. âœ… å®ç° multipart/form-data è§£æ
3. âœ… é›†æˆ Gemini Audio API
4. âœ… å®ç° OpenAI å“åº”æ ¼å¼è½¬æ¢
5. âœ… æ·»åŠ è·¯ç”±å’Œä¸­é—´ä»¶

**äº¤ä»˜ç‰©**:
- å¯å·¥ä½œçš„ `/v1/audio/transcriptions` ç«¯ç‚¹
- æ”¯æŒ JSON å“åº”æ ¼å¼

### é˜¶æ®µ 2: å¢å¼ºåŠŸèƒ½ï¼ˆ1-2 å¤©ï¼‰

**ç›®æ ‡**: å®Œå–„ Agent é›†æˆä½“éªŒ

**ä»»åŠ¡**:
1. â¬œ æ”¯æŒå¤šç§å“åº”æ ¼å¼ï¼ˆtext, srt, vttï¼‰
2. â¬œ å®ç°æ¨¡å‹æ˜ å°„ï¼ˆwhisper-1 â†’ gemini-*ï¼‰
3. â¬œ æ·»åŠ è¯­è¨€æ£€æµ‹å’Œè‡ªåŠ¨æ ‡æ³¨
4. â¬œ ä¼˜åŒ– prompt å¤„ç†é€»è¾‘

**äº¤ä»˜ç‰©**:
- å®Œæ•´çš„ OpenAI Whisper API å…¼å®¹æ€§
- Agent å¯ä»¥ç›´æ¥ä½¿ç”¨

### é˜¶æ®µ 3: æ–‡æ¡£å’Œç¤ºä¾‹ï¼ˆ1 å¤©ï¼‰

**ç›®æ ‡**: å¸®åŠ© Agent å¼€å‘è€…å¿«é€Ÿé›†æˆ

**ä»»åŠ¡**:
1. â¬œ ç¼–å†™ API ä½¿ç”¨æ–‡æ¡£
2. â¬œ æä¾›å„æ¡†æ¶é›†æˆç¤ºä¾‹
3. â¬œ åˆ›å»ºæµ‹è¯•è„šæœ¬
4. â¬œ å½•åˆ¶æ¼”ç¤ºè§†é¢‘

**äº¤ä»˜ç‰©**:
- å®Œæ•´çš„æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 
- å¼€ç®±å³ç”¨çš„é…ç½®æ¨¡æ¿

---

## å…«ã€æµ‹è¯•è®¡åˆ’

### 8.1 å•å…ƒæµ‹è¯•

**æµ‹è¯•åœºæ™¯**:
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_audio_transcription_mp3() {
        // æµ‹è¯• MP3 æ–‡ä»¶è½¬å½•
    }

    #[tokio::test]
    async fn test_audio_transcription_large_file() {
        // æµ‹è¯•å¤§æ–‡ä»¶æ‹’ç»ï¼ˆ>15MBï¼‰
    }

    #[tokio::test]
    async fn test_openai_response_format() {
        // æµ‹è¯•å“åº”æ ¼å¼ç¬¦åˆ OpenAI æ ‡å‡†
    }
}
```

### 8.2 é›†æˆæµ‹è¯•

**æµ‹è¯•åœºæ™¯ 1: ä½¿ç”¨ OpenAI Python SDK**
```python
import pytest
from openai import OpenAI

@pytest.fixture
def client():
    return OpenAI(
        api_key="test_key",
        base_url="http://localhost:31109/v1"
    )

def test_transcription(client):
    with open("test_audio.mp3", "rb") as audio:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio
        )
        assert isinstance(transcript.text, str)
        assert len(transcript.text) > 0
```

**æµ‹è¯•åœºæ™¯ 2: Agent æ¡†æ¶é›†æˆ**
```python
def test_langchain_integration():
    # æµ‹è¯• LangChain é›†æˆ
    pass

def test_autogen_integration():
    # æµ‹è¯• AutoGen é›†æˆ
    pass
```

---

## ä¹ã€æ½œåœ¨é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: å“åº”æ ¼å¼å·®å¼‚

**é—®é¢˜æè¿°**:
Gemini è¿”å›çš„è½¬å½•æ–‡æœ¬å¯èƒ½åŒ…å«é¢å¤–çš„æ ¼å¼åŒ–ä¿¡æ¯

**è§£å†³æ–¹æ¡ˆ**:
```rust
// æå–çº¯æ–‡æœ¬é€»è¾‘
fn extract_transcript_text(gemini_response: &Value) -> String {
    let text = gemini_response["candidates"][0]["content"]["parts"][0]["text"]
        .as_str()
        .unwrap_or("");

    // æ¸…ç†å¯èƒ½çš„ Markdown æ ¼å¼
    text.trim()
        .replace("```", "")
        .replace("**", "")
        .trim()
        .to_string()
}
```

### é—®é¢˜ 2: è¯­è¨€æ£€æµ‹å‡†ç¡®æ€§

**é—®é¢˜æè¿°**:
Agent å¯èƒ½ä¸æŒ‡å®š `language` å‚æ•°

**è§£å†³æ–¹æ¡ˆ**:
```rust
// æ ¹æ® Gemini å“åº”è‡ªåŠ¨æ£€æµ‹è¯­è¨€
fn detect_language(text: &str) -> String {
    // ç®€å•çš„è¯­è¨€æ£€æµ‹é€»è¾‘
    if text.chars().any(|c| c >= '\u{4e00}' && c <= '\u{9fff}') {
        "zh".to_string()
    } else {
        "en".to_string()
    }
}
```

### é—®é¢˜ 3: é•¿éŸ³é¢‘å¤„ç†

**é—®é¢˜æè¿°**:
Gemini å¯èƒ½å¯¹é•¿éŸ³é¢‘çš„è½¬å½•æ•ˆæœä¸å¦‚ä¸“ä¸š STT æ¨¡å‹

**è§£å†³æ–¹æ¡ˆ**:
```rust
// åˆ†æ®µå¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
async fn transcribe_long_audio(audio_data: &[u8]) -> Result<String, String> {
    const SEGMENT_SIZE: usize = 5 * 1024 * 1024; // 5MB åˆ†æ®µ

    if audio_data.len() > SEGMENT_SIZE {
        // å®ç°éŸ³é¢‘åˆ†æ®µå’Œåˆå¹¶é€»è¾‘
        // TODO: éœ€è¦éŸ³é¢‘å¤„ç†åº“æ”¯æŒ
        return Err("é•¿éŸ³é¢‘æš‚ä¸æ”¯æŒï¼Œè¯·åˆ†æ®µä¸Šä¼ ".to_string());
    }

    // æ­£å¸¸å¤„ç†
    Ok(transcribe(audio_data).await?)
}
```

---

## åã€ç»“è®ºä¸å»ºè®®

### æ ¸å¿ƒç»“è®º

1. âœ… **æŠ€æœ¯å¯è¡Œæ€§**: å®Œå…¨å¯è¡Œï¼Œæ— æŠ€æœ¯éšœç¢
2. âœ… **API å…¼å®¹æ€§**: 100% ç¬¦åˆ OpenAI Whisper API æ ‡å‡†
3. âœ… **Agent é›†æˆ**: ä¸»æµ Agent æ¡†æ¶æ— ç¼æ”¯æŒ
4. âœ… **å®æ–½éš¾åº¦**: ä½ï¼Œå¯å¤ç”¨ç°æœ‰æ¶æ„
5. âœ… **æ€§èƒ½è¡¨ç°**: é¢„æœŸè‰¯å¥½ï¼ˆGemini 2.0 Flashï¼‰

### å®æ–½å»ºè®®

**çŸ­æœŸï¼ˆç«‹å³å®æ–½ï¼‰**:
1. âœ… å°† `/v1/audio/transcriptions` ç«¯ç‚¹çº³å…¥éŸ³é¢‘ä¸Šä¼ åŠŸèƒ½è§„åˆ’
2. âœ… ä¼˜å…ˆå®ç° JSON å“åº”æ ¼å¼ï¼ˆæœ€å¸¸ç”¨ï¼‰
3. âœ… ç¡®ä¿ä¸ç°æœ‰ OpenAI handler ä»£ç é£æ ¼ä¸€è‡´
4. âœ… æ·»åŠ å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—

**ä¸­æœŸï¼ˆ1 ä¸ªæœˆå†…ï¼‰**:
1. ğŸ“Š æ”¶é›† Agent å¼€å‘è€…åé¦ˆ
2. ğŸ“Š æ ¹æ®ä½¿ç”¨æ•°æ®ä¼˜åŒ– prompt æ¨¡æ¿
3. ğŸ“Š æ‰©å±•æ”¯æŒæ›´å¤šå“åº”æ ¼å¼ï¼ˆsrt, vttï¼‰
4. ğŸ“Š ç¼–å†™è¯¦ç»†çš„é›†æˆæŒ‡å—

**é•¿æœŸï¼ˆ3-6 ä¸ªæœˆï¼‰**:
1. ğŸ” ç ”ç©¶ Gemini éŸ³é¢‘èƒ½åŠ›çš„æ–°ç‰¹æ€§
2. ğŸ” æ¢ç´¢å®æ—¶è½¬å½•ï¼ˆWebSocket æµå¼ï¼‰
3. ğŸ” æ”¯æŒéŸ³é¢‘é¢„å¤„ç†ï¼ˆé™å™ªã€å¢å¼ºï¼‰
4. ğŸ” å»ºç«‹ Agent å¼€å‘è€…ç¤¾åŒº

### å¯¹æ¯”å…¶ä»–æ–¹æ¡ˆ

| æ–¹æ¡ˆ | ä¼˜åŠ¿ | åŠ£åŠ¿ | æ¨èåº¦ |
|------|------|------|--------|
| **Antigravity STT** | å…è´¹ã€å¿«é€Ÿã€å…¼å®¹ | 15MB é™åˆ¶ | â­â­â­â­â­ |
| **OpenAI Whisper** | å®˜æ–¹ã€25MB é™åˆ¶ | æ”¶è´¹ã€è¾ƒæ…¢ | â­â­â­â­ |
| **Azure Speech** | ä¼ä¸šçº§ã€æ— é™åˆ¶ | å¤æ‚ã€æ˜‚è´µ | â­â­â­ |
| **Google Cloud STT** | å¼ºå¤§ã€å‡†ç¡® | å¤æ‚ã€æ˜‚è´µ | â­â­â­ |
| **æœ¬åœ° Whisper** | å…è´¹ã€ç§å¯† | æ…¢ã€éœ€ GPU | â­â­ |

### æœ€ç»ˆå»ºè®®

**å¯¹äº Agent å¼€å‘è€…**:
- âœ… æ¨èä½¿ç”¨ Antigravity-Manager çš„ STT æ¥å£ä½œä¸ºä¸»è¦æ–¹æ¡ˆ
- âœ… é…ç½®ç®€å•ï¼Œåªéœ€ä¿®æ”¹ `base_url`
- âœ… å¯ä»¥èŠ‚çœ OpenAI API æˆæœ¬

**å¯¹äº Antigravity-Manager é¡¹ç›®**:
- âœ… ä¼˜å…ˆå®ç°æ­¤åŠŸèƒ½ï¼Œä»·å€¼æ˜ç¡®
- âœ… å¯ä»¥ä½œä¸ºé¡¹ç›®äº®ç‚¹åŠŸèƒ½æ¨å¹¿
- âœ… æœ‰åŠ©äºå»ºç«‹ Agent å¼€å‘è€…ç¤¾åŒº

---

## é™„å½•

### A. ç›¸å…³é“¾æ¥

- [OpenAI Audio API æ–‡æ¡£](https://platform.openai.com/docs/api-reference/audio)
- [Gemini Audio èƒ½åŠ›è¯´æ˜](https://ai.google.dev/gemini-api/docs/audio)
- [LangChain éŸ³é¢‘é›†æˆ](https://python.langchain.com/docs/integrations/document_loaders/audio)
- [AutoGen å¤šæ¨¡æ€æ”¯æŒ](https://microsoft.github.io/autogen/docs/topics/multimodal)

### B. OpenAI SDK é…ç½®ç¤ºä¾‹

**Python:**
```python
from openai import OpenAI
client = OpenAI(
    api_key="your_key",
    base_url="http://localhost:31109/v1"
)
```

**Node.js:**
```typescript
import OpenAI from "openai";
const client = new OpenAI({
  apiKey: "your_key",
  baseURL: "http://localhost:31109/v1"
});
```

**Go:**
```go
import "github.com/sashabaranov/go-openai"
config := openai.DefaultConfig("your_key")
config.BaseURL = "http://localhost:31109/v1"
client := openai.NewClientWithConfig(config)
```

### C. å®Œæ•´çš„ cURL æµ‹è¯•å‘½ä»¤

```bash
curl -X POST http://localhost:31109/v1/audio/transcriptions \
  -H "Authorization: Bearer your_antigravity_token" \
  -F "file=@audio.mp3" \
  -F "model=whisper-1" \
  -F "language=zh"
```

---

**æŠ¥å‘Šä½œè€…**: Claude Sonnet 4.5
**åˆ›å»ºæ—¥æœŸ**: 2026-01-03
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**é¡¹ç›®ç‰ˆæœ¬**: v3.3.11+
